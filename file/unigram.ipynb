{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk.corpus\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "k=pd.read_excel(\"fake_news_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_pattern = '\\s+'\n",
    "url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|''[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "englishword_num ='[a-zA-Z]|[0-9]+'\n",
    "AmhPunc='[፤።፡፣:,.?/()•“”*፨]+'\n",
    "special_char = \"[፥@#$%^&=?×!,;:_.(){}`'+*<>\\\"¤—„\\® ̄™¡¡\\x10»€«·‘0e1b§”¬¦...\"\"f÷\\~ ̈©±¥£¶–°• ̃’“|]\"\n",
    "geez_number='[፩፪፫፬፭፮፯፰፱፲፳፴፵፶፷፸፹፺፻] ' # for removing geez number\n",
    "RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "emoji_pattern = re.compile(\"[\"u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                 u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                 u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                 u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
    "                                 u\"\\U00002702-\\U000027B0\"\n",
    "                                 u\"\\U000024C2-\\U0001F251\"\n",
    "                                 \"]+\", flags=re.UNICODE)\n",
    "haa='[ሃ]'; he='[ሐ]'; hu='[ሑ]'; hi='[ሒ]'; ha='[ሓ]'; hie='[ሔ]'; h='[ሕ]'; ho='[ሖ]'; he1='[ኀ]'; hu1='[ኁ]'; hi1='[ኂ]'; ha1='[ኃ]'; hie1='[ኄ]'; h1='[ኅ]'; ho1='[ኆ]';\n",
    "se='[ሠ]'; su='[ሡ]'; si='[ሢ]'; sa='[ሣ]'; sie='[ሤ]'; s='[ሥ]'; so='[ሦ]'; \n",
    "aa1='[ኣ]'; ae='[ዐ]'; au='[ዑ]'; ai='[ዒ]'; aa='[ዓ]'; aie='[ዔ]'; e='[ዕ]'; ao='[ዖ]';\n",
    "tse='[ጸ]'; tsu='[ጹ]'; tsi='[ጺ]'; tsa='[ጻ]'; tsie='[ጼ]'; ts='[ጽ]'; tso='[ጾ]';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "corpus=[]\n",
    "for i in range(0,len(k)):\n",
    "    Clean_text = re.sub(url_regex,'', str(k['Actual_Post'][i]))\n",
    "    Clean_text = re.sub(AmhPunc,' ',Clean_text)\n",
    "    Clean_text=re.sub(special_char,' ',Clean_text)\n",
    "    Clean_text= re.sub(englishword_num,'',Clean_text)\n",
    "    Clean_text= re.sub(r'(.)\\1+', r'\\1\\1',Clean_text) #removingelongation in text\n",
    "    Clean_text = RE_EMOJI.sub(r'', Clean_text)\n",
    "    Clean_text =re.sub(geez_number,'',Clean_text)\n",
    "    Clean_text=re.sub('-','',Clean_text)\n",
    "    Clean_text=re.sub(r'<[^>]*>','', Clean_text)\n",
    "    Clean_text = Clean_text.replace(\"\\\\\", \"\");\n",
    "    Clean_text = Clean_text.replace(\"[\", \"\");\n",
    "    Clean_text = Clean_text.replace(\"]\", \"\");\n",
    "    Clean_text = emoji_pattern.sub(r'', Clean_text)\n",
    "    Clean_text = re.sub(space_pattern,' ',Clean_text)\n",
    "    ##################################################\n",
    "    Clean_text= re.sub(he,'ሀ',Clean_text); \n",
    "    Clean_text= re.sub(hu,'ሁ',Clean_text);\n",
    "    Clean_text= re.sub(hi,'ሂ',Clean_text);\n",
    "    Clean_text= re.sub(ha,'ሀ',Clean_text); \n",
    "    Clean_text= re.sub(hie,'ሄ',Clean_text);\n",
    "    Clean_text= re.sub(h,'ህ',Clean_text);\n",
    "    Clean_text= re.sub(ho,'ሆ',Clean_text);\n",
    "    Clean_text= re.sub(haa,'ሀ',Clean_text);\n",
    "    #######################################################\n",
    "    Clean_text= re.sub(he1,'ሀ',Clean_text) \n",
    "    Clean_text= re.sub(hu1,'ሁ',Clean_text) \n",
    "    Clean_text= re.sub(hi1,'ሂ',Clean_text)\n",
    "    Clean_text= re.sub(ha1,'ሀ',Clean_text)\n",
    "    Clean_text= re.sub(hie1,'ሄ',Clean_text)\n",
    "    Clean_text= re.sub(h1,'ህ',Clean_text)\n",
    "    Clean_text= re.sub(ho1,'ሆ',Clean_text)\n",
    "    ##########################################################\n",
    "    Clean_text= re.sub(se,'ሰ',Clean_text) \n",
    "    Clean_text= re.sub(su,'ሱ',Clean_text)\n",
    "    Clean_text= re.sub(si,'ሲ',Clean_text)\n",
    "    Clean_text= re.sub(sa,'ሳ',Clean_text)\n",
    "    Clean_text= re.sub(sie,'ሴ',Clean_text) \n",
    "    Clean_text= re.sub(s,'ስ', Clean_text)\n",
    "    Clean_text= re.sub(so,'ሶ',Clean_text)\n",
    "    ###################################################\n",
    "    Clean_text= re.sub(ae,'አ',Clean_text) \n",
    "    Clean_text= re.sub(au,'ኡ',Clean_text)\n",
    "    Clean_text= re.sub(ai,'ኢ',Clean_text)\n",
    "    Clean_text= re.sub(aa,'አ',Clean_text) \n",
    "    Clean_text= re.sub(aie,'ኤ',Clean_text)\n",
    "    Clean_text= re.sub(e,'እ',Clean_text)\n",
    "    Clean_text= re.sub(ao,'ኦ',Clean_text)\n",
    "    Clean_text= re.sub(aa1,'አ',Clean_text)\n",
    "    #############################################\n",
    "    Clean_text= re.sub(tse,'ፀ',Clean_text) \n",
    "    Clean_text= re.sub(tsu,'ፁ',Clean_text) \n",
    "    Clean_text= re.sub(tsi,'ፂ',Clean_text)\n",
    "    Clean_text= re.sub(tsa,'ፃ',Clean_text) \n",
    "    Clean_text= re.sub(tsie,'ፄ',Clean_text)\n",
    "    Clean_text= re.sub(ts,'ፅ',Clean_text)\n",
    "    Clean_text= re.sub(tso,'ፆ',Clean_text)\n",
    "    Clean_text= Clean_text.split()\n",
    "    Clean_text = ' '.join(Clean_text)\n",
    "    corpus.append(Clean_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[]\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "tokenized_sents = [word_tokenize(i) for i in corpus]\n",
    "for i in tokenized_sents:\n",
    "    #print(i)\n",
    "    tokens.append(i)\n",
    "    \n",
    "tokens=[[word for word in article if len(word)>1]for article in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stopword=[]\n",
    "with open('stopworrrrd.txt','r' ,encoding='utf8') as f:\n",
    "    f.readline()\n",
    "    for i in f:\n",
    "       \n",
    "        stopword.append(re.sub('[\\n]+', '',str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_stopword_remove=[]\n",
    "after_stopword_remove=[[word for word in article if word not in stopword]for article in tokens]\n",
    "after_stopword_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=0\n",
    "for j in after_stopword_remove:\n",
    "    with open('C:/Users/MenbiAmel/Music/fake news detection/file/'+str(kk)+'.txt','w', encoding='utf8') as f:\n",
    "        for listitem in j:\n",
    "            f.write('%s\\n' % listitem)\n",
    "    kk+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string,l3\n",
    "#stopwordsl=mymodule.importing_files_for_stopwords()\n",
    "for i in range(0,4589):\n",
    "    document='C:/Users/MenbiAmel/Music/fake news detection/file/'+str(i)+'.txt'\n",
    "    l3.anal_file('am', document,'C:/Users/MenbiAmel/Music/fake news detection/Post_Stemmed/'+str(i)+'.csv', root=False, gram=False,nbest=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#   እንዲሁም  \n",
    "for i in range(0,4589):\n",
    "    unstemmed_word=open('C:/Users/MenbiAmel/Music/fake news detection/file/'+str(i)+'.txt','r',encoding=\"utf8\")\n",
    "    unstemmed_wordm=unstemmed_word.read()\n",
    "    unstemmed_wordarray=[]\n",
    "    unstemmed_wordmarray=unstemmed_wordm\n",
    "    unstemmed_wordmtostrng=\"\".join(unstemmed_wordmarray)\n",
    "    unstemmed_wordm_final=unstemmed_wordmtostrng.split()\n",
    "    unstemmed_wordm_final2=[]\n",
    "    for ss in unstemmed_wordm_final:\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        ss = [w.translate(table) for w in ss]\n",
    "        ss=\"\".join(ss)\n",
    "        unstemmed_wordm_final2.append(ss)\n",
    "\n",
    "    df=pd.read_csv('C:/Users/MenbiAmel/Music/fake news detection/Post_Stemmed/'+str(i)+'.csv',sep=\";\",names=['word:'])\n",
    "    final_stemmed_val=[]\n",
    "    for k in range(0,len(df)):\n",
    "        x=df.iloc[k,0]  \n",
    "        final_stemmed_val.append(x)\n",
    "    \n",
    "    words_to_stemm=[]\n",
    "    for xx in unstemmed_wordm_final2:\n",
    "        adding_word_suffix='word: '+xx\n",
    "        words_to_stemm.append(adding_word_suffix)\n",
    "    ff=[]\n",
    "    for yy in range(0,len(final_stemmed_val)):\n",
    "        if final_stemmed_val[yy] not in words_to_stemm:\n",
    "            ff.append(final_stemmed_val[yy])\n",
    "    \n",
    "    jj=[]\n",
    "    for mm in range(0,len(ff)):\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        term_to_stem = [w.translate(table) for w in ff[mm]]\n",
    "        term_to_stem=\"\".join(term_to_stem)\n",
    "       # term_to_stem= term_to_stem.split()\n",
    "        if term_to_stem==\"\":\n",
    "            continue\n",
    "        elif len(term_to_stem)<2:\n",
    "            continue\n",
    "        else:\n",
    "            jj.append(term_to_stem)\n",
    "    mmm=\" \".join(jj)\n",
    "    mid_file = open('C:/Users/MenbiAmel/Music/fake news detection/Stemmed_puncR/'+str(i)+'.txt', \"w\",encoding=\"utf8\")\n",
    "    mid_file.write((mmm))\n",
    "    mid_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemed_file=[]\n",
    "\n",
    "for i in range(0,4590):\n",
    "    unstemmed_word=open('C:/Users/MenbiAmel/Music/fake news detection/Stemmed_puncR/'+str(i)+'.txt','r',encoding=\"utf8\")\n",
    "    unstemmed_wordm=unstemmed_word.read()\n",
    "    unstemmed_wordarray=[]\n",
    "    unstemmed_wordmarray=unstemmed_wordm\n",
    "    stemed_file.append(unstemmed_wordmarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem=[]\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "stemed_sents = [word_tokenize(j) for j in stemed_file]\n",
    "for j in stemed_sents:\n",
    "    #print(i)\n",
    "    stem.append(j)\n",
    "    \n",
    "stem=[[word for word in article if len(word)>2]for article in stem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def tokenizer_text(file):\n",
    "    stem=[]\n",
    "    stemed_sents = [word_tokenize(j) for j in file]\n",
    "    for j in stemed_sents:\n",
    "        stem.append(j)\n",
    "    stem=[[word for word in article if len(word)>2]for article in stem]\n",
    "    return stem\n",
    "    \n",
    "stem=tokenizer_text(stemed_file)\n",
    "stem\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfv=TfidfVectorizer(ngram_range=(1,1),use_idf=True, smooth_idf=True)\n",
    "x=tfidfv.fit_transform(stemed_file).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=k['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfv.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape,X_test.shape,X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import  LogisticRegression\n",
    "logreg=LogisticRegression(C=1e5, max_iter=10000)\n",
    "logreg.fit(X_train, y_train)\n",
    "pred = logreg.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print('Accuracy of LogisticRegression  classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of LogisticRegression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test)))\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, pred)\n",
    "plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,cross_val_predict,cross_validate\n",
    "cvscore1=cross_val_score(logreg,x,np.ravel(y),cv=5)\n",
    "y_pred=cross_val_predict(logreg,x,np.ravel(y),cv=5)\n",
    "cvscore1,cvscore1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of LogisticRegression with cv:'+str(cvscore1.mean()))\n",
    "cm = metrics.confusion_matrix(y, y_pred)\n",
    "plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totacu=round((metrics.accuracy_score(y,y_pred)*100),3)\n",
    "totacu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totMisacu=round((1-metrics.accuracy_score(y,y_pred))*100,3)\n",
    "totMisacu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_Real=round((metrics.recall_score(y,y_pred,pos_label='Real'))*100,3)\n",
    "recall_Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_Fake=round((metrics.recall_score(y,y_pred,pos_label='Fake'))*100,3)\n",
    "recall_Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_real=round((metrics.precision_score(y,y_pred,pos_label='Real'))*100,3);\n",
    "precision_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_Fake=round((metrics.precision_score(y,y_pred,pos_label='Fake'))*100,3);\n",
    "precision_Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_Real=round(2*((recall_Real*precision_real)/(recall_Real+precision_real)),3)\n",
    "f1_score_Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_Fake=round(2*((recall_Fake*precision_Fake)/(recall_Fake+precision_Fake)),3)\n",
    "f1_score_Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svmmodel_w2v= LinearSVC(C=0.01, multi_class='ovr', max_iter=10000, \n",
    "                        class_weight='balanced',penalty='l2' )\n",
    "svmmodel_w2v=svmmodel_w2v.fit(X_train, y_train)\n",
    "pred = svmmodel_w2v.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print('Accuracy of support vector machine   classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of support vector machine classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test)))\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, pred)\n",
    "plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscore2=cross_val_score(svmmodel_w2v,x,np.ravel(y),cv=5)\n",
    "y_pred=cross_val_predict(svmmodel_w2v,x,np.ravel(y),cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscore2,cvscore2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of support vector machine cv:'+str(cvscore2.mean()))\n",
    "cm = metrics.confusion_matrix(y, y_pred)\n",
    "plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totacu=round((metrics.accuracy_score(y,y_pred)*100),3)\n",
    "totacu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totMisacu=round((1-metrics.accuracy_score(y,y_pred))*100,3)\n",
    "totMisacu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_Real=round((metrics.recall_score(y,y_pred,pos_label='Real'))*100,3)\n",
    "recall_Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_Fake=round((metrics.recall_score(y,y_pred,pos_label='Fake'))*100,3)\n",
    "recall_Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_real=round((metrics.precision_score(y,y_pred,pos_label='Real'))*100,3);\n",
    "precision_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_Fake=round((metrics.precision_score(y,y_pred,pos_label='Fake'))*100,3);\n",
    "precision_Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_Real=round(2*((recall_Real*precision_real)/(recall_Real+precision_real)),3)\n",
    "f1_score_Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_Fake=round(2*((recall_Fake*precision_Fake)/(recall_Fake+precision_Fake)),3)\n",
    "f1_score_Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Random=RandomForestClassifier(n_estimators=400, n_jobs=4)\n",
    "Random.fit(X_train, y_train)\n",
    "pred = Random.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print('Accuracy of RandomForest  classifier on training set: {:.2f}'\n",
    "     .format(Random.score(X_train, y_train)))\n",
    "print('Accuracy of RandomForest classifier on test set: {:.2f}'\n",
    "     .format(Random.score(X_test, y_test)))\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, pred)\n",
    "plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Random=RandomForestClassifier(n_estimators=400, n_jobs=4)\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict,cross_validate\n",
    "cvscore3=cross_val_score(Random,x,np.ravel(y),cv=5)\n",
    "y_pred=cross_val_predict(Random,x,np.ravel(y),cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscore3,cvscore3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totacu=round((metrics.accuracy_score(y,y_pred)*100),3)\n",
    "totacu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totMisacu=round((1-metrics.accuracy_score(y,y_pred))*100,3)\n",
    "totMisacu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_Real=round((metrics.recall_score(y,y_pred,pos_label='Real'))*100,3)\n",
    "recall_Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_Fake=round((metrics.recall_score(y,y_pred,pos_label='Fake'))*100,3)\n",
    "recall_Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_real=round((metrics.precision_score(y,y_pred,pos_label='Real'))*100,3);\n",
    "precision_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_Fake=round((metrics.precision_score(y,y_pred,pos_label='Fake'))*100,3);\n",
    "precision_Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_Real=round(2*((recall_Real*precision_real)/(recall_Real+precision_real)),3)\n",
    "f1_score_Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_Fake=round(2*((recall_Fake*precision_Fake)/(recall_Fake+precision_Fake)),3)\n",
    "f1_score_Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y, y_pred)\n",
    "plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
